{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-x4v_2coXBri"
      },
      "outputs": [],
      "source": [
        "# hide\n",
        "import sys\n",
        "if 'google.colab' in sys.modules: \n",
        "    !pip install -U wwf transformers datasets >> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrSkFe1BXBrm"
      },
      "outputs": [],
      "source": [
        "#all_slow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oN3TYLKvXBrm"
      },
      "source": [
        "# Text Classification with Transformers (Intermediate)\n",
        "\n",
        "> Fine-tuning pre-trained LM from HuggingFace model hub on GLUE benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6m_TofGRXBro"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "from wwf.utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "61aqcy0JXBro"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from fastai.text.all import *\n",
        "\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from inspect import signature\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ka_iZMmnXBrp",
        "outputId": "cc5be118-97b4-4861-8818-6acd8d5c55cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/markdown": "\n---\nThis article is also a Jupyter Notebook available to be run from the top down. There\nwill be code snippets that you can then run in any environment.\n\nBelow are the versions of `fastai`, `fastcore`, `transformers`, and `datasets` currently running at the time of writing this:\n* `fastai` : 2.5.3 \n* `fastcore` : 1.3.27 \n* `transformers` : 4.16.2 \n* `datasets` : 1.18.3 \n---",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#hide_input\n",
        "state_versions(['fastai', 'fastcore', 'transformers', 'datasets'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKWWLehxXBrq"
      },
      "source": [
        "## Setup\n",
        "\n",
        "In this notebook we will look at how to conbine the power of [HuggingFace](https://huggingface.co/) with great flexibility of [fastai](https://www.fast.ai/). For this purpose we will be finetuning `distilroberta-base` on The [General Language Understanding Evaluation(GLUE) benchmark](https://gluebenchmark.com/) tasks.\n",
        "\n",
        "To give you a grasp on what are we dealing with, here is a brief summary of GLUE tasks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9ekFQq_XBrr",
        "outputId": "2aef22b5-4259-4174-8cdb-0a857f3a0950"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Task description</th>\n",
              "      <th>Size</th>\n",
              "      <th>Metrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cola</th>\n",
              "      <td>Corpus of Linguistic Acceptability</td>\n",
              "      <td>Determine whether it is a grammatical sentence</td>\n",
              "      <td>8.5k</td>\n",
              "      <td>matthews_corrcoef</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sst2</th>\n",
              "      <td>Stanford Sentiment Treebank</td>\n",
              "      <td>Predict the sentiment of a givensentence</td>\n",
              "      <td>67k</td>\n",
              "      <td>accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mrpc</th>\n",
              "      <td>Microsoft Research Paraphrase Corpus</td>\n",
              "      <td>Determine whether the sentences in the pair are semantically equivalent</td>\n",
              "      <td>3.7k</td>\n",
              "      <td>f1/accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stsb</th>\n",
              "      <td>Semantic Textual Similarity Benchmark</td>\n",
              "      <td>Determine similarity score for 2 sentences</td>\n",
              "      <td>7k</td>\n",
              "      <td>pearsonr/spearmanr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qqp</th>\n",
              "      <td>Quora question pair</td>\n",
              "      <td>Determine if 2 questions are the same (paraphrase)</td>\n",
              "      <td>364k</td>\n",
              "      <td>f1/accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mnli</th>\n",
              "      <td>Mulit-Genre Natural Language Inference</td>\n",
              "      <td>Predict whether the premise entails, contradicts or is neutral to the hypothesis</td>\n",
              "      <td>393k</td>\n",
              "      <td>accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qnli</th>\n",
              "      <td>Stanford Question Answering Dataset</td>\n",
              "      <td>Determine whether the context sentence containsthe answer to the question</td>\n",
              "      <td>105k</td>\n",
              "      <td>accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rte</th>\n",
              "      <td>Recognize Textual Entailment</td>\n",
              "      <td>Determine whether one sentece entails another</td>\n",
              "      <td>2.5k</td>\n",
              "      <td>accuracy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wnli</th>\n",
              "      <td>Winograd Schema Challenge</td>\n",
              "      <td>Predict if the sentence with the pronoun substituted is entailed by the original sentence</td>\n",
              "      <td>634</td>\n",
              "      <td>accuracy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#hide_input\n",
        "abreviations=[\"cola\",\"sst2\",\"mrpc\",\"stsb\",\"qqp\",\"mnli\",\"qnli\",\"rte\",\"wnli\"]\n",
        "name = [\n",
        "    \"Corpus of Linguistic Acceptability\",\n",
        "    \"Stanford Sentiment Treebank\",\n",
        "    \"Microsoft Research Paraphrase Corpus\",\n",
        "    \"Semantic Textual Similarity Benchmark\",\n",
        "    \"Quora question pair\",\n",
        "    \"Mulit-Genre Natural Language Inference\",\n",
        "    \"Stanford Question Answering Dataset\",\n",
        "    \"Recognize Textual Entailment\",\n",
        "    \"Winograd Schema Challenge\"\n",
        "]\n",
        "descriptions = [\n",
        "    \"Determine whether it is a grammatical sentence\",\n",
        "    \"Predict the sentiment of a givensentence\",\n",
        "    \"Determine whether the sentences in the pair are semantically equivalent\",\n",
        "    \"Determine similarity score for 2 sentences\",\n",
        "    \"Determine if 2 questions are the same (paraphrase)\",\n",
        "    \"Predict whether the premise entails, contradicts or is neutral to the hypothesis\",\n",
        "    \"Determine whether the context sentence containsthe answer to the question\",\n",
        "    \"Determine whether one sentece entails another\",\n",
        "    \"Predict if the sentence with the pronoun substituted is entailed by the original sentence\"\n",
        "]\n",
        "df = pd.DataFrame({'Name':name,\n",
        "                   'Task description':descriptions,\n",
        "                   'Size':['8.5k','67k','3.7k','7k','364k','393k','105k','2.5k', '634'],\n",
        "                   'Metrics':['matthews_corrcoef','accuracy','f1/accuracy','pearsonr/spearmanr',\n",
        "                              'f1/accuracy','accuracy','accuracy','accuracy','accuracy']},\n",
        "                   index=abreviations)\n",
        "display_df(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7Zy1zmrXBrt"
      },
      "source": [
        "Let's define main settings for the run in one place. You can choose any model from wide variety presented in HuggingFace model hub. Some might need special treatment to work but most models of appropriate class should be plug-and-play."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPqRKo-WXBru"
      },
      "outputs": [],
      "source": [
        "ds_name = 'glue'\n",
        "model_name = \"distilroberta-base\"\n",
        "\n",
        "max_len = 512\n",
        "bs = 32\n",
        "val_bs = bs*2\n",
        "\n",
        "n_epoch = 4\n",
        "lr = 2e-5\n",
        "opt_func = Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68W7mbr-XBru"
      },
      "source": [
        "To make switching between datasets smooth I'll define couple of dictionaries containing per-task information. We'll need metrics, text fields to retrieve data and number of outputs for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5VYC2zjXBrv"
      },
      "outputs": [],
      "source": [
        "GLUE_TASKS = [\"cola\", \"mnli\", \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst2\", \"stsb\", \"wnli\"]\n",
        "def validate_task():\n",
        "    assert task in GLUE_TASKS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE5hywvaXBrv"
      },
      "outputs": [],
      "source": [
        "glue_metrics = {\n",
        "    'cola':[MatthewsCorrCoef()],\n",
        "    'sst2':[accuracy],\n",
        "    'mrpc':[F1Score(), accuracy],\n",
        "    'stsb':[PearsonCorrCoef(), SpearmanCorrCoef()],\n",
        "    'qqp' :[F1Score(), accuracy],\n",
        "    'mnli':[accuracy],\n",
        "    'qnli':[accuracy],\n",
        "    'rte' :[accuracy],\n",
        "    'wnli':[accuracy],\n",
        "}\n",
        "\n",
        "glue_textfields = {\n",
        "    'cola':['sentence', None],\n",
        "    'sst2':['sentence', None],\n",
        "    'mrpc':['sentence1', 'sentence2'],\n",
        "    'stsb':['sentence1', 'sentence2'],\n",
        "    'qqp' :['question1', 'question2'],\n",
        "    'mnli':['premise', 'hypothesis'],\n",
        "    'qnli':['question', 'sentence'],\n",
        "    'rte' :['sentence1', 'sentence2'],\n",
        "    'wnli':['sentence1', 'sentence2'],\n",
        "}\n",
        "\n",
        "glue_num_labels = {'mnli':3, 'stsb':1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crhym6HMXBrv"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2go6FB69XBrw"
      },
      "source": [
        "We'll be using `datasets` library for HuggingFace to get data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zse7w3alXBrw",
        "outputId": "39fe9f31-818b-4b6a-9d3c-4ead28033824"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ]
        }
      ],
      "source": [
        "task = 'mrpc'; validate_task()\n",
        "ds = load_dataset(ds_name, task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z1yCirGXBrw"
      },
      "source": [
        "MNLI datasets contains 2 sets for validation: matched and missmatched. The mathced set is selected here for validation when fine-tuning on MNLI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SFQxvg_XBrx",
        "outputId": "fce1fbcd-c957-4223-e88d-40f10dcf53dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3668, 408)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_ = 'validation-matched' if task=='mnli' else 'validation'\n",
        "len(ds['train']), len(ds[valid_])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3no3NuO6XBrx"
      },
      "outputs": [],
      "source": [
        "nt, nv = len(ds['train']), len(ds[valid_])\n",
        "train_idx, valid_idx = L(range(nt)), L(range(nt, nt+nv))\n",
        "train_ds = concatenate_datasets([ds['train'], ds[valid_]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdEKvKHFXBrx"
      },
      "source": [
        "One can inspect single example for the given task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vu2ZeOkJXBrx",
        "outputId": "875bae43-4a3b-4310-b7cf-0b717d8d0949"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'idx': 0,\n",
              " 'label': 1,\n",
              " 'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
              " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ds[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra3k8fxsXBry"
      },
      "source": [
        "Here I use number of characters a proxy for length of tokenized text to speed up `dls` creation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U30HSg4AXBry",
        "outputId": "eabf52ef-bb23-4c70-a438-2b42958776fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#hide_output\n",
        "lens = train_ds.map(lambda s: {'len': sum([len(s[i]) for i in glue_textfields[task] if i])},\n",
        "                    remove_columns=train_ds.column_names, num_proc=2, keep_in_memory=True)\n",
        "train_lens = lens.select(train_idx)['len']\n",
        "valid_lens = lens.select(valid_idx)['len']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU3EAOIsXBry"
      },
      "source": [
        "## DataBlock and Transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s16V5qw7XBrz"
      },
      "source": [
        "`TextGetter` is analogous to `ItemGetter` but retrieves either one or two text fields from the source (e.g. \"sentence1\" and \"sentence2\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CuboWshXBrz"
      },
      "outputs": [],
      "source": [
        "class TextGetter(ItemTransform):\n",
        "    def __init__(self, s1='text', s2=None):\n",
        "        self.s1, self.s2 = s1, s2\n",
        "    def encodes(self, sample):\n",
        "        if self.s2 is None: return sample[self.s1]\n",
        "        else: return sample[self.s1], sample[self.s2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JT2lcRzXBrz"
      },
      "source": [
        "Transformers expect two parts of text to be concatenated with some `SEP` token in between. But when displaying the batch it's better to have those texts in separate columns for better readability. To make it work I define a version of `show_batch` to be dispatched on the `TransTensorText` class. It will handle cases when there is single decoded text or a tuple of two texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnSYWchqXBrz"
      },
      "outputs": [],
      "source": [
        "class TransTensorText(TensorBase): pass\n",
        "\n",
        "@typedispatch\n",
        "def show_batch(x:TransTensorText, y, samples, ctxs=None, max_n=10, trunc_at=150, **kwargs):\n",
        "    if ctxs is None: ctxs = get_empty_df(min(len(samples), max_n))\n",
        "    if isinstance(samples[0][0], tuple):\n",
        "        samples = L((*s[0], *s[1:]) for s in samples)\n",
        "        if trunc_at is not None: samples = L((s[0].truncate(trunc_at), s[1].truncate(trunc_at), *s[2:]) for s in samples)\n",
        "    if trunc_at is not None: samples = L((s[0].truncate(trunc_at),*s[1:]) for s in samples)\n",
        "    ctxs = show_batch[object](x, y, samples, max_n=max_n, ctxs=ctxs, **kwargs)\n",
        "    display_df(pd.DataFrame(ctxs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp1gSnf3XBrz"
      },
      "outputs": [],
      "source": [
        "#collapse\n",
        "def find_first(t, e):\n",
        "    for i, v in enumerate(t):\n",
        "        if v == e: return i\n",
        "        \n",
        "def split_by_sep(t, sep_tok_id):\n",
        "    idx = find_first(t, sep_tok_id)\n",
        "    return t[:idx], t[idx:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpbewTnoXBr0"
      },
      "source": [
        "Tokenization of the inputs will be done by `TokBatchTransform` which wraps pre-trained HuggingFace tokenizer. The text processing is done in batches for speed-up. We want to awoid explicit python loops when possible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6UBgpZVXBr0"
      },
      "outputs": [],
      "source": [
        "class TokBatchTransform(Transform):\n",
        "    \"\"\"\n",
        "    Tokenizes texts in batches using pretrained HuggingFace tokenizer.\n",
        "    The first element in a batch can be single string or 2-tuple of strings.\n",
        "    If `with_labels=True` the \"labels\" are added to the output dictionary.\n",
        "    \"\"\"\n",
        "    def __init__(self, pretrained_model_name=None, tokenizer_cls=AutoTokenizer, \n",
        "                 config=None, tokenizer=None, with_labels=False,\n",
        "                 padding=True, truncation=True, max_length=None, **kwargs):\n",
        "        if tokenizer is None:\n",
        "            tokenizer = tokenizer_cls.from_pretrained(pretrained_model_name, config=config)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.kwargs = kwargs\n",
        "        self._two_texts = False\n",
        "        store_attr()\n",
        "    \n",
        "    def encodes(self, batch):\n",
        "        # batch is a list of tuples of ({text or (text1, text2)}, {targets...})\n",
        "        if is_listy(batch[0][0]): # 1st element is tuple\n",
        "            self._two_texts = True\n",
        "            texts = ([s[0][0] for s in batch], [s[0][1] for s in batch])\n",
        "        elif is_listy(batch[0]): \n",
        "            texts = ([s[0] for s in batch],)\n",
        "\n",
        "        inps = self.tokenizer(*texts,\n",
        "                              add_special_tokens=True,\n",
        "                              padding=self.padding,\n",
        "                              truncation=self.truncation,\n",
        "                              max_length=self.max_length,\n",
        "                              return_tensors='pt',\n",
        "                              **self.kwargs)\n",
        "        # inps are batched, collate targets into batches too\n",
        "        labels = default_collate([s[1:] for s in batch])\n",
        "        if self.with_labels:\n",
        "            inps['labels'] = labels[0]\n",
        "            res = (inps, )\n",
        "        else:\n",
        "            res = (inps, ) + tuple(labels)\n",
        "        return res\n",
        "    \n",
        "    def decodes(self, x:TransTensorText):\n",
        "        if self._two_texts:\n",
        "            x1, x2 = split_by_sep(x, self.tokenizer.sep_token_id)\n",
        "            return (TitledStr(self.tokenizer.decode(x1.cpu(), skip_special_tokens=True)),\n",
        "                    TitledStr(self.tokenizer.decode(x2.cpu(), skip_special_tokens=True)))\n",
        "        return TitledStr(self.tokenizer.decode(x.cpu(), skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HNSMZuQXBr0"
      },
      "source": [
        "The batches processed by `TokBatchTransform` contain a dictionary as the first element. For decoding it's handy to have a tensor instead. The `Undict` transform fethces `input_ids` from the batch and creates `TransTensorText` which should work with typedispatch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvviyIaNXBr0"
      },
      "outputs": [],
      "source": [
        "class Undict(Transform):\n",
        "    def decodes(self, x:dict):\n",
        "        if 'input_ids' in x: res = TransTensorText(x['input_ids'])\n",
        "        return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGh1MtbUXBr0"
      },
      "source": [
        "Now the transforms are to be combined inside a data block to be used for `dls` creation. The inputs are prebatched by `TokBatchTranform` so we don't need to use `fa_collate` for batching, so `fa_convert` is passed in as for \"create_batch\".\n",
        "\n",
        "The texts we processing are of different lengths. Each sample in the batch is padded to the length of longest input to make them \"collatable\". Shuffling samples randomly will therefor result in getting longer batches on average. As the compute time depends on the sequence length this is udesired. `SortedDL` groups the inputs by length and if `shuffle=True` those are shuffled within certain interval keeping samples of similar length together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4WyWqgvXBr1"
      },
      "outputs": [],
      "source": [
        "dls_kwargs = {\n",
        "    'before_batch': TokBatchTransform(pretrained_model_name=model_name, max_length=max_len),\n",
        "    'create_batch': fa_convert\n",
        "}\n",
        "text_block = TransformBlock(dl_type=SortedDL, dls_kwargs=dls_kwargs, batch_tfms=Undict(), )\n",
        "\n",
        "dblock = DataBlock(blocks = [text_block, CategoryBlock()],\n",
        "                   get_x=TextGetter(*glue_textfields[task]),\n",
        "                   get_y=ItemGetter('label'),\n",
        "                   splitter=IndexSplitter(valid_idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSVXnjWQXBr1",
        "outputId": "5e3b637d-8f9c-4fae-921f-bf22e8b2cb2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 2.92 s, sys: 858 ms, total: 3.78 s\n",
            "Wall time: 3.79 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "dl_kwargs=[{'res':train_lens}, {'val_res':valid_lens}]\n",
        "dls = dblock.dataloaders(train_ds, bs=bs, val_bs=val_bs, dl_kwargs=dl_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bGLEOVfXBr1",
        "outputId": "1e361ecf-0aa9-4d10-f104-94f2088d607a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Securities and Exchange Commission yesterday said companies trading on the biggest U.S. markets must win shareholder approval before granting stock options and other stock-based compensation plans to corporate executives.</td>\n",
              "      <td>Companies trading on the biggest stock markets must get shareholder approval before granting stock options and other equity compensation under rules cleared yesterday by the Securities and Exchange Commission.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\" The investigation appears to be focused on certain accounting practices common to the interactive entertainment industry, with specific emphasis on revenue recognition, \" Activision said in an SEC filing.</td>\n",
              "      <td>According to the company filings, the investigation \" appears to be focused on certain accounting practices common to the interactive entertainment industry, with specific emphasis on revenue recognition. \"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The U.N. nuclear watchdog reprimanded Iran on Thursday for failing to comply with its nuclear safeguards obligations and called on Tehran to unconditionally accept stricter inspections by the agency.</td>\n",
              "      <td>The U.N. atomic watchdog rapped Iran Thursday for failing to comply with nuclear safeguards, issuing a statement Washington said underlined international opposition to Tehran developing any banned weapons.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Microsoft favors setting up \" independent e-mail trust authorities to establish and maintain commercial email guidelines, certify senders who follow the guidelines, and resolve customer disputes. \"</td>\n",
              "      <td>Gates says he wants to see \" independent e-mail trust authorities \" who \" establish and maintain commercial email guidelines, certify senders who follow the guidelines, and resolve customer disputes. \"</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dls.show_batch(max_n=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PloWJUikXBr2"
      },
      "source": [
        "## Customized Learner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FVXbFpOXBr2"
      },
      "source": [
        "Now the `xb` we get from dataloader contains a dictionary and HuggingFace transformers accept keyword argument as input. But fastai `Learner` feeds the model with a sequence of positional arguments (`self.pred = self.model(*self.xb)`). To make this work smoothly we can create a callback to handle unrolling of the input dict into proper `xb` tuple.\n",
        "\n",
        "But first we need to define some utility functions. `default_splitter` is used to divide model parameters into groups:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H6rROQtXBr2"
      },
      "outputs": [],
      "source": [
        "def default_splitter(model):\n",
        "    groups = L(model.base_model.children()) + L(m for m in list(model.children())[1:] if params(m))\n",
        "    return groups.map(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Oeg3ADZXBr2"
      },
      "source": [
        "Similar to `show_batch` one have to customize `show_results`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHi9mVqFXBr2"
      },
      "outputs": [],
      "source": [
        "@typedispatch\n",
        "def show_results(x: TransTensorText, y, samples, outs, ctxs=None, max_n=10, trunc_at=150, **kwargs):\n",
        "    if ctxs is None: ctxs = get_empty_df(min(len(samples), max_n))\n",
        "    if isinstance(samples[0][0], tuple):\n",
        "        samples = L((*s[0], *s[1:]) for s in samples)\n",
        "        if trunc_at is not None: samples = L((s[0].truncate(trunc_at), s[1].truncate(trunc_at), *s[2:]) for s in samples)\n",
        "    elif trunc_at is not None: samples = L((s[0].truncate(trunc_at),*s[1:]) for s in samples)\n",
        "    ctxs = show_results[object](x, y, samples, outs, ctxs=ctxs, max_n=max_n, **kwargs)\n",
        "    display_df(pd.DataFrame(ctxs))\n",
        "    return ctxs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xS8EWUSXBr3"
      },
      "source": [
        "`TransLearner` itself doesn't do much: it adds `TransCallback` and sets `splitter` to be `default_splitter` if `None` is provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfhmMbM5XBr3"
      },
      "outputs": [],
      "source": [
        "@delegates(Learner.__init__)\n",
        "class TransLearner(Learner):\n",
        "    \"Learner for training transformers from HuggingFace\"\n",
        "    def __init__(self, dls, model, **kwargs):\n",
        "        splitter = kwargs.get('splitter', None)\n",
        "        if splitter is None: kwargs['splitter'] = default_splitter\n",
        "        super().__init__(dls, model, **kwargs)\n",
        "        self.add_cb(TransCallback(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf8FfJotXBr3"
      },
      "source": [
        "Main piece of work needed to train transformers model happens in `TransCallback`. It saves valid model argument and makes input dict yielded by dataloader into a tuple.\n",
        "\n",
        "By default the model returns a dictionary-like object containing `logits` and possibly other outputs as defined by model config (e.g. intermediate hidden representations). In the fastai training loop we usually expect `preds` to be a tensor containing model predictions (logits). The callback formats the preds properly.\n",
        "\n",
        "Notice that if `labels` are found in the input, transformer models compute the `loss` and return it together with output `logits`. The callback below is designed to utilise the loss returned by model instead of recomputing it using `learn.loss_func`. This is not actually used in this example but might be handy in some use cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYCiOTcRXBr3"
      },
      "outputs": [],
      "source": [
        "class TransCallback(Callback):\n",
        "    \"Handles HuggingFace model inputs and outputs\"\n",
        "    \n",
        "    def __init__(self, model):\n",
        "        self.labels = tuple()\n",
        "        self.model_args = {k:v.default for k, v in signature(model.forward).parameters.items()}\n",
        "    \n",
        "    def before_batch(self):\n",
        "        if 'labels' in self.xb[0].keys():\n",
        "            self.labels = (self.xb[0]['labels'], )\n",
        "        # make a tuple containing an element for each argument model excepts\n",
        "        # if argument is not in xb it is set to default value\n",
        "        self.learn.xb = tuple([self.xb[0].get(k, self.model_args[k]) for k in self.model_args.keys()])\n",
        "    \n",
        "    def after_pred(self):\n",
        "        if 'loss' in self.pred:\n",
        "            self.learn.loss_grad = self.pred.loss\n",
        "            self.learn.loss = self.pred.loss.clone()\n",
        "        self.learn.pred = self.pred.logits\n",
        "    \n",
        "    def after_loss(self):\n",
        "        if len(self.labels):\n",
        "            self.learn.yb = self.labels\n",
        "            self.labels = tuple()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y0xtCIRXBr3"
      },
      "source": [
        "## Training\n",
        "\n",
        "After all the preparations the training is streightforward. Setting `num_labels` for the model and choosing apropriate metrics is automated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK-D1AmVXBr3",
        "outputId": "0264317a-c8e6-42e6-8beb-d8f4d9906376"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#hide_output\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=glue_num_labels.get(task, 2))\n",
        "metrics = glue_metrics[task]\n",
        "learn = TransLearner(dls, model, metrics=metrics, opt_func=opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpRqMrnlXBr4",
        "outputId": "554cc257-fb6e-43f4-ec13-41d865670d13"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification (Input shape: 32)\n",
              "============================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "============================================================================\n",
              "                     32 x 101 x 768      \n",
              "Embedding                                 38603520   True      \n",
              "Embedding                                 394752     True      \n",
              "Embedding                                 768        True      \n",
              "LayerNorm                                 1536       True      \n",
              "Dropout                                                        \n",
              "Linear                                    590592     True      \n",
              "Linear                                    590592     True      \n",
              "Linear                                    590592     True      \n",
              "Dropout                                                        \n",
              "Linear                                    590592     True      \n",
              "LayerNorm                                 1536       True      \n",
              "Dropout                                                        \n",
              "____________________________________________________________________________\n",
              "                     32 x 101 x 3072     \n",
              "Linear                                    2362368    True      \n",
              "____________________________________________________________________________\n",
              "                     32 x 101 x 768      \n",
              "Linear                                    2360064    True      \n",
              "LayerNorm                                 1536       True      \n",
              "Dropout                                                        \n",
              "Linear                                    590592     True      \n",
              "Linear                                    590592     True      \n",
              "Linear                                    590592     True      \n",
              "Dropout                                                        \n",
              "Linear                                    590592     True      \n",
              "LayerNorm                                 1536       True      \n",
              "Dropout                                                        \n",
              "____________________________________________________________________________\n",
              "                     32 x 101 x 3072     \n",
              "Linear                                    2362368    True      \n",
              "____________________________________________________________________________\n",
              "                     32 x 101 x 768      \n",
              "Linear                                    2360064    True      \n",
              "LayerNorm                                 1536       True      \n",
              "Dropout                                                        \n",
              "Linear                                    590592     True      \n",
              "Linear                                    590592     True      \n",
              "Linear                                    590592     True      \n",
              "Dropout                                                        \n",
              "Linear                                    590592     True      \n",
              "LayerNorm                                 1536       True      \n",
              "Dropout                                                        \n",
              "____________________________________________________________________________\n",
              "                     32 x 101 x 3072     \n",
              "Linear                                    2362368    True      \n",
              "____________________________________________________________________________\n",
              "                     32 x 101 x 768      \n",
              "Linear                                    2360064    True      \n",
              "LayerNorm                                 1536       True      \n",
              "Dropout                                                        \n",
              "Linear                                    590592     True      \n",
              "Linear                                    590592     True      \n",
              "Linear                                    590592     True      \n",
              "Dropout                                                        \n",
              "Linear                                    590592     True      \n",
              "LayerNorm                                 1536       True      \n",
              "Dropout                                                        \n",
              "____________________________________________________________________________\n",
              "                     32 x 101 x 3072     \n",
              "Linear                                    2362368    True      \n",
              "____________________________________________________________________________\n",
              "                     32 x 101 x 768      \n",
              "Linear                                    2360064    True      \n",
              "LayerNorm                                 1536       True      \n",
              "Dropout                                                        \n",
              "Linear                                    590592     True      \n",
              "Linear                                    590592     True      \n",
              "Linear                                    590592     True      \n",
              "Dropout                                                        \n",
              "Linear                                    590592     True      \n",
              "LayerNorm                                 1536       True      \n",
              "Dropout                                                        \n",
              "____________________________________________________________________________\n",
              "                     32 x 101 x 3072     \n",
              "Linear                                    2362368    True      \n",
              "____________________________________________________________________________\n",
              "                     32 x 101 x 768      \n",
              "Linear                                    2360064    True      \n",
              "LayerNorm                                 1536       True      \n",
              "Dropout                                                        \n",
              "Linear                                    590592     True      \n",
              "Linear                                    590592     True      \n",
              "Linear                                    590592     True      \n",
              "Dropout                                                        \n",
              "Linear                                    590592     True      \n",
              "LayerNorm                                 1536       True      \n",
              "Dropout                                                        \n",
              "____________________________________________________________________________\n",
              "                     32 x 101 x 3072     \n",
              "Linear                                    2362368    True      \n",
              "____________________________________________________________________________\n",
              "                     32 x 101 x 768      \n",
              "Linear                                    2360064    True      \n",
              "LayerNorm                                 1536       True      \n",
              "Dropout                                                        \n",
              "Linear                                    590592     True      \n",
              "Dropout                                                        \n",
              "____________________________________________________________________________\n",
              "                     32 x 2              \n",
              "Linear                                    1538       True      \n",
              "____________________________________________________________________________\n",
              "\n",
              "Total params: 82,119,938\n",
              "Total trainable params: 82,119,938\n",
              "Total non-trainable params: 0\n",
              "\n",
              "Optimizer used: <function Adam at 0x7fa9069c1268>\n",
              "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - TransCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#collapse_output\n",
        "learn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVJLM8AXXBr4",
        "outputId": "c1a654f2-1119-4af0-8979-492e1daddf18"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.599429</td>\n",
              "      <td>0.508199</td>\n",
              "      <td>0.832551</td>\n",
              "      <td>0.737745</td>\n",
              "      <td>00:21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.436955</td>\n",
              "      <td>0.337732</td>\n",
              "      <td>0.892193</td>\n",
              "      <td>0.857843</td>\n",
              "      <td>00:22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.318495</td>\n",
              "      <td>0.331339</td>\n",
              "      <td>0.900175</td>\n",
              "      <td>0.860294</td>\n",
              "      <td>00:22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.232149</td>\n",
              "      <td>0.354381</td>\n",
              "      <td>0.897747</td>\n",
              "      <td>0.855392</td>\n",
              "      <td>00:22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Better model found at epoch 0 with f1_score value: 0.8325508607198748.\n",
            "Better model found at epoch 1 with f1_score value: 0.8921933085501859.\n",
            "Better model found at epoch 2 with f1_score value: 0.9001751313485115.\n"
          ]
        }
      ],
      "source": [
        "metric_to_monitor = metrics[0].name if isinstance(metrics[0], Metric) else metrics[0].__name__\n",
        "cbs = [SaveModelCallback(monitor=metric_to_monitor)]\n",
        "learn.fit_one_cycle(4, lr, cbs=cbs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC4scSgAXBr4"
      },
      "source": [
        "After training the model it's useful to verify  that results make sense:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlytnJ-6XBr4",
        "outputId": "a044783a-057a-442d-c47d-9b645a67c42c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "      <th>category</th>\n",
              "      <th>category_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The delegates said raising and distributing funds has been complicated by the U.S. crackdown on jihadi charitable foundations, bank accounts of terror-related organizations and money transfers.</td>\n",
              "      <td>Bin Laden ’ s men pointed out that raising and distributing funds has been complicated by the U.S. crackdown on jihadi charitable foundations, bank accounts of terror-related organizations and money transfers.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The attack followed several days of disturbances in the city where American soldiers exchanged fire with an unknown number of attackers as civilians carried out demonstrations against the American presence.</td>\n",
              "      <td>The attack came after several days of disturbance in the city in which U.S. soldiers exchanged fire with an unknown number of attackers as civilians protested the American presence.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Massachusetts regulators and the Securities and Exchange Commission on Tuesday pressed securities fraud charges against Putnam Investments and two of its former portfolio managers for alleged improper mutual fund trading.</td>\n",
              "      <td>State and federal securities regulators filed civil charges against Putnam Investments and two portfolio managers in the ever-expanding mutual fund trading scandal.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Justice Minister Martin Cauchon and Prime Minister Jean Chrétien have both said the Liberal government will introduce legislation soon to decriminalize possession of small amounts of pot for personal use.</td>\n",
              "      <td>Justice Minister Martin Cauchon and Prime Minister Jean Chretien both have said the government will introduce legislation to decriminalize possession of small amounts of pot.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Myanmar's pro-democracy leader Aung San Suu Kyi will return home late Friday but will remain in detention after recovering from surgery at a Yangon hospital, her personal physician said.</td>\n",
              "      <td>Myanmar's pro-democracy leader Aung San Suu Kyi will be kept under house arrest following her release from a hospital where she underwent surgery, her personal physician said Friday.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>President Bush raised a record-breaking $ 49.5 million for his re-election campaign over the last three months, with contributions from 262,000 Americans, the president's campaign chairman said Tuesday.</td>\n",
              "      <td>President Bush has raised $ 83.9 million since beginning his re-election campaign in May, and has $ 70 million of that left to spend, his campaign said Tuesday.</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Barry Callebaut will be able to use Brach's retail network to sell products made from its German subsidiary Stollwerck, which makes chocolate products not sold in the United States.</td>\n",
              "      <td>Barry Callebaut will be able to use Brach's retail network to sell products made from its German subsidiary Stollwerck, which makes chocolate products unknown to the American market.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Donations stemming from the Sept. 11 attacks helped push up contributions to human service organizations and large branches of the United Way by 15 percent and 28.6 percent, respectively.</td>\n",
              "      <td>Donations stemming from the Sept. 11 attacks helped push up contributions to human service organizations by 15 percent and to large branches of the United Way by 28.6 percent.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The Guru microcontroller serves four functions : hardware monitoring, overclocking management, BIOS ( Basic Input Output System ) update and a troubleshooting-assistance feature called Black Box.</td>\n",
              "      <td>The µGuru microcontroller serves four functions : hardware monitoring, overclocking management, BIOS update and a troubleshooting-assistance feature called Black Box.</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "learn.show_results()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUZ8Cwc2XBr5"
      },
      "source": [
        "Finally we can run our model on test set to get the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywBbueo-XBr5",
        "outputId": "3e0829d8-ef0a-46b6-ee5f-87ca3a9bf988"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "tensor([[0.0121, 0.9879],\n",
              "        [0.1296, 0.8704],\n",
              "        [0.0072, 0.9928],\n",
              "        ...,\n",
              "        [0.0159, 0.9841],\n",
              "        [0.0046, 0.9954],\n",
              "        [0.1612, 0.8388]])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_dl = dls.test_dl(ds['test'])\n",
        "preds = learn.get_preds(dl=test_dl)\n",
        "preds[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb4uAqY8XBr5"
      },
      "source": [
        "## Final remarks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP1K3mRHXBr5"
      },
      "source": [
        "Generalised versions of \"wrapper\" code used in this notebook can be found in [fasthugs](https://github.com/aikindergarten/fasthugs) library. Also you can check out some extra info on fine-tuning models on GLUE tasks in [this blogpost](https://arampacha.github.io/thoughtsamples/fastai/huggingface/transformers/2021/05/07/glue-benchmark.html). Another option for training HuggingFace transformers with fastai is using [blurr](https://github.com/ohmeow/blurr) library."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "07_nlp.external.transformers-glue.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}